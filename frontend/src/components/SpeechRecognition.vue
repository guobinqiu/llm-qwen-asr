<template>
  <div>
    <h2>é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«æµ‹è¯•</h2>

    <button
      @mousedown="start"
      @mouseup="stop"
      @touchstart.prevent="start"
      @touchend.prevent="stop"
      :class="{ recording: recording }"
    >
      {{ recording ? 'ğŸ™ï¸ è¯†åˆ«ä¸­...ï¼ˆæ¾å¼€åœæ­¢ï¼‰' : 'æŒ‰ä½è¯´è¯' }}
    </button>

    <div>
      <h3>è¯†åˆ«ç»“æœï¼š</h3>
      <div>{{ currentTranscript }}</div>
    </div>
  </div>
</template>

<script>
export default {
  data() {
    return {
      ws: null,
      audioCtx: null,
      scriptNode: null,
      recording: false,
      currentTranscript: '',
      sampleRate: 16000,
      audioStream: null,
    }
  },
  methods: {
    async start() {
      this.recording = true

      // åˆå§‹åŒ– WebSocketï¼ˆå¦‚æœå°šæœªè¿æ¥ï¼‰
      if (!this.ws || this.ws.readyState === WebSocket.CLOSED) {
        this.ws = new WebSocket(`ws://${location.hostname}:8080/ws`)
        this.ws.binaryType = 'arraybuffer'

        this.ws.onmessage = (e) => {
          const text = e.data.trim()
          console.log('Received:', text)
          this.currentTranscript = text
        }

        this.ws.onerror = () => console.error('WebSocketé”™è¯¯')
        this.ws.onclose = () => console.log('WebSocketå·²å…³é—­')
      }

      if (!this.audioStream) {
        this.audioStream = await navigator.mediaDevices.getUserMedia({ audio: true })
      }

      this.audioCtx = new (window.AudioContext || window.webkitAudioContext)()
      const inputRate = this.audioCtx.sampleRate
      const source = this.audioCtx.createMediaStreamSource(this.audioStream)
      this.scriptNode = this.audioCtx.createScriptProcessor(1024, 1, 1)

      this.scriptNode.onaudioprocess = (e) => {
        const input = e.inputBuffer.getChannelData(0)
        const pcm = this.resampleToPCM(input, inputRate, this.sampleRate)
        if (pcm) {
          this.ws.send(pcm)
        }
      }

      source.connect(this.scriptNode)
      this.scriptNode.connect(this.audioCtx.destination)

      // å¯åŠ¨å®šæ—¶å™¨ï¼Œæ¯éš” 5 ç§’å‘é€ä¸€æ¬¡é™éŸ³éŸ³é¢‘
      // this.silenceInterval = setInterval(() => {
      //   if (this.ws.readyState === WebSocket.OPEN) {
      //     this.sendSilentAudio()
      //   }
      // }, 5000)
    },

    stop() {
      this.recording = false

      // æ¸…ç†å®šæ—¶å™¨ï¼Œåœæ­¢å‘é€é™éŸ³éŸ³é¢‘
      // if (this.silenceInterval) {
      //   clearInterval(this.silenceInterval)
      //   this.silenceInterval = null
      // }

      // å»¶è¿Ÿ500msï¼Œç¡®ä¿éŸ³é¢‘æ•°æ®å®Œå…¨å‘é€
      // setTimeout(() => {
      //   this.scriptNode && this.scriptNode.disconnect()
      //   this.audioCtx && this.audioCtx.close()
      //   this.audioCtx = null
      // }, 500)
    },

    resampleToPCM(input, fromRate, toRate) {
      const ratio = fromRate / toRate
      const newLen = Math.round(input.length / ratio)
      const output = new Int16Array(newLen)
      for (let i = 0; i < newLen; i++) {
        const s = Math.max(-1, Math.min(1, input[Math.floor(i * ratio)]))
        output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF
      }
      return new Uint8Array(output.buffer)
    },
     // å‘é€é™éŸ³éŸ³é¢‘
    // sendSilentAudio() {
    //   const silentAudio = new ArrayBuffer(1024);  // åˆ›å»ºä¸€ä¸ªç©ºçš„éŸ³é¢‘æ•°æ®å—ï¼Œè¡¨ç¤ºé™éŸ³ï¼ˆä¾‹å¦‚å…¨é›¶çš„ PCM æ•°æ®ï¼‰
    //   if (this.ws.readyState === WebSocket.OPEN) {
    //     this.ws.send(silentAudio)
    //   }
    // },
  }
}
</script>

<style>
button.recording {
  background-color: red;
  color: white;
}
</style>
